{\rtf1\ansi\ansicpg1252\deff0\nouicompat\deflang1033{\fonttbl{\f0\fmodern JetBrains Mono;}{\f1\fnil\fcharset0 Calibri;}}
{\colortbl ;\red207\green142\blue109;\red188\green190\blue196;\red86\green168\blue245;\red122\green126\blue133;\red170\green73\blue38;\red136\green136\blue198;\red42\green172\blue184;\red106\green171\blue115;}
{\*\generator Riched20 10.0.22621}\viewkind4\uc1 
\pard\box\brdrdash\brdrw0 \sa200\sl276\slmult1\cf1\f0\fs20\lang9 import \cf2 pandas \cf1 as \cf2 pd\line\cf1 import \cf2 numpy \cf1 as \cf2 np\line\cf1 from \cf2 numpy.ma.core \cf1 import \cf2 ceil\line\cf1 from \cf2 scipy.spatial \cf1 import \cf2 distance\line\cf1 from \cf2 sklearn.preprocessing \cf1 import \cf2 MinMaxScaler\line\cf1 from \cf2 sklearn.model_selection \cf1 import \cf2 train_test_split\line\cf1 from \cf2 sklearn.metrics \cf1 import \cf2 accuracy_score, confusion_matrix\line\cf1 import \cf2 matplotlib.pyplot \cf1 as \cf2 plt\line\cf1 from \cf2 matplotlib \cf1 import \cf2 colors\line\line\cf1 def \cf3 minmax_scaler\cf2 (data):\line     \cf4 # Separate numeric and non-numeric columns\line     \cf2 numeric_cols = data.select_dtypes(\cf5 include\cf2 =np.number).columns\line     non_numeric_cols = \cf6 list\cf2 (\cf6 set\cf2 (data.columns) - \cf6 set\cf2 (numeric_cols))\line\line     \cf4 # Scale numeric columns\line     \cf2 numeric_data = data[numeric_cols]\line     scaler = MinMaxScaler()\line     scaled_numeric = scaler.fit_transform(numeric_data)\line\line     \cf4 # Check for and replace NaN and infinite values\line     \cf2 scaled_numeric = np.nan_to_num(scaled_numeric)\line\line     \cf4 # One-hot encode non-numeric columns\line     \cf2 non_numeric_data = pd.get_dummies(data[non_numeric_cols])\line\line     \cf4 # Concatenate scaled numeric and one-hot encoded non-numeric data\line     \cf2 scaled_data = np.concatenate([scaled_numeric, non_numeric_data], \cf5 axis\cf2 =\cf7 1\cf2 )\line\line     \cf1 return \cf2 scaled_data\line\line\cf1 def \cf3 e_distance\cf2 (x, y):\line     \cf1 if \cf2 x.ndim > \cf7 1\cf2 :\line         x = x.flatten()\line     \cf1 if \cf2 y.ndim > \cf7 1\cf2 :\line         y = y.flatten()\line     \cf1 return \cf2 distance.euclidean(x, y)\line\line\cf1 def \cf3 m_distance\cf2 (x, y):\line     \cf1 return \cf2 distance.cityblock(x, y)\line\line\cf1 def \cf3 winning_neuron\cf2 (data, t, som, num_rows, num_cols):\line     winner = [\cf7 0\cf2 , \cf7 0\cf2 ]\line     shortest_distance = np.sqrt(data.shape[\cf7 1\cf2 ])\line     input_data = data[t][:, np.newaxis] \cf1 if \cf2 data[t].ndim == \cf7 1 \cf1 else \cf2 data[t]\line     \cf1 for \cf2 row \cf1 in \cf6 range\cf2 (num_rows):\line         \cf1 for \cf2 col \cf1 in \cf6 range\cf2 (num_cols):\line             dist = e_distance(som[row][col], input_data)\line             \cf1 if \cf2 dist < shortest_distance:\line                 shortest_distance = dist\line                 winner = [row, col]\line     \cf1 return \cf2 winner\line\line\cf1 def \cf3 decay\cf2 (step, max_steps, max_learning_rate, max_neighbourhood_range):\line     coefficient = \cf7 1.0 \cf2 - (np.float64(step) / max_steps)\line     learning_rate = coefficient * max_learning_rate\line     neighbourhood_range = ceil(coefficient * max_neighbourhood_range)\line     \cf1 return \cf2 learning_rate, neighbourhood_range\line\line\cf1 def \cf3 som_training\cf2 (train_data, num_rows, num_cols, max_neighbourhood_range, max_learning_rate, max_steps):\line     num_dims = train_data.shape[\cf7 1\cf2 ]\line     np.random.seed(\cf7 40\cf2 )\line     som = np.random.random_sample(\cf5 size\cf2 =(num_rows, num_cols, num_dims))\line\line     \cf1 for \cf2 step \cf1 in \cf6 range\cf2 (max_steps):\line         \cf1 if \cf2 (step + \cf7 1\cf2 ) % \cf7 1000 \cf2 == \cf7 0\cf2 :\line             \cf6 print\cf2 (\cf8 "Iteration: "\cf2 , step + \cf7 1\cf2 )\line\line         learning_rate, neighbourhood_range = decay(step, max_steps, max_learning_rate, max_neighbourhood_range)\line\line         t = np.random.randint(\cf7 0\cf2 , \cf5 high\cf2 =train_data.shape[\cf7 0\cf2 ])\line         winner = winning_neuron(train_data, t, som, num_rows, num_cols)\line\line         \cf1 for \cf2 row \cf1 in \cf6 range\cf2 (num_rows):\line             \cf1 for \cf2 col \cf1 in \cf6 range\cf2 (num_cols):\line                 \cf1 if \cf2 m_distance([row, col], winner) <= neighbourhood_range:\line                     som[row][col] += learning_rate * (train_data[t] - som[row][col])\line\line     \cf6 print\cf2 (\cf8 "SOM training completed"\cf2 )\line     \cf1 return \cf2 som\line\line\cf1 def \cf3 label_som_nodes\cf2 (train_data_norm, train_y, num_rows, num_cols, som):\line     label_map = np.full((num_rows, num_cols), \cf1 None\cf2 , \cf5 dtype\cf2 =\cf6 object\cf2 )\line\line     \cf1 for \cf2 t \cf1 in \cf6 range\cf2 (train_data_norm.shape[\cf7 0\cf2 ]):\line         winner = winning_neuron(train_data_norm, t, som, num_rows, num_cols)\line         row, col = winner\line         label = train_y.iloc[t].item()  \cf4 # Convert Series to a simple value\line\line         \cf1 if \cf2 label_map[row, col] \cf1 is None\cf2 :\line             label_map[row, col] = [label]\line         \cf1 else\cf2 :\line             label_map[row, col].append(label)\line\line     \cf1 for \cf2 i \cf1 in \cf6 range\cf2 (num_rows):\line         \cf1 for \cf2 j \cf1 in \cf6 range\cf2 (num_cols):\line             \cf1 if \cf2 label_map[i, j] \cf1 is not None\cf2 :\line                 label_map[i, j] = \cf6 max\cf2 (\cf6 set\cf2 (label_map[i, j]), \cf5 key\cf2 =label_map[i, j].count)\line\line     \cf1 return \cf2 label_map\line\line\cf1 def \cf3 evaluate_accuracy\cf2 (test_data, test_y, som, label_map, num_rows, num_cols):\line     winner_labels = []\line\line     \cf1 for \cf2 t \cf1 in \cf6 range\cf2 (test_data.shape[\cf7 0\cf2 ]):\line         input_data = test_data[t][:, np.newaxis] \cf1 if \cf2 test_data[t].ndim == \cf7 1 \cf1 else \cf2 test_data[t]\line         winner = winning_neuron(input_data, t, som, num_rows, num_cols)\line         row = winner[\cf7 0\cf2 ]\line         col = winner[\cf7 1\cf2 ]\line         predicted = label_map[row][col]\line         winner_labels.append(predicted)\line\line     \cf4 # Convert winner_labels to match the format of test_y\line     \cf2 unique_labels_test = np.unique(test_y)\line     label_dict_test = \{label: idx \cf1 for \cf2 idx, label \cf1 in \cf6 enumerate\cf2 (unique_labels_test)\}\line     winner_labels_numeric = np.array([label_dict_test[label] \cf1 for \cf2 label \cf1 in \cf2 winner_labels])\line\line     accuracy = accuracy_score(test_y, winner_labels_numeric)\line     \cf1 return \cf2 accuracy\line\line\line\cf4 # Load dataset\line\cf1 from \cf2 ucimlrepo \cf1 import \cf2 fetch_ucirepo\line automobile = fetch_ucirepo(\cf5 id\cf2 =\cf7 10\cf2 )\line X = automobile.data.features\line y = automobile.data.targets\line\line\cf4 # Split the dataset into training and testing sets\line\cf2 train_x, test_x, train_y, test_y = train_test_split(X, y, \cf5 test_size\cf2 =\cf7 0.2\cf2 , \cf5 random_state\cf2 =\cf7 42\cf2 )\line\cf6 print\cf2 (train_x.shape, train_y.shape, test_x.shape, test_y.shape)  \cf4 # check the shapes\line\line # Hyperparameters for SOM\line\cf2 num_rows = \cf7 10\line\cf2 num_cols = \cf7 10\line\cf2 max_neighbourhood_range = \cf7 4\line\cf2 max_learning_rate = \cf7 0.5\line\cf2 max_steps = \cf6 int\cf2 (\cf7 7.5 \cf2 * \cf7 10e3\cf2 )\line\line\cf4 # Train SOM\line\cf2 train_data = pd.concat([train_x, train_y], \cf5 axis\cf2 =\cf7 1\cf2 )\line train_data_norm = minmax_scaler(train_data)\line som = som_training(train_data_norm, num_rows, num_cols, max_neighbourhood_range, max_learning_rate, max_steps)\line\line\cf4 # Label the SOM nodes\line\cf2 label_map = label_som_nodes(train_data_norm, train_y, num_rows, num_cols, som)\line\line\cf4 # Evaluate accuracy on the test set\line\cf2 test_data_norm = minmax_scaler(test_x)\line accuracy = evaluate_accuracy(test_data_norm, test_y, som, label_map, num_rows, num_cols)\line\line\cf6 print\cf2 (\cf8 "Accuracy: "\cf2 , accuracy)\line\par
\cf1 import \cf2 pandas \cf1 as \cf2 pd\line\cf1 import \cf2 numpy \cf1 as \cf2 np\line\cf1 from \cf2 numpy.ma.core \cf1 import \cf2 ceil\line\cf1 from \cf2 scipy.spatial \cf1 import \cf2 distance\line\cf1 from \cf2 sklearn.preprocessing \cf1 import \cf2 MinMaxScaler\line\cf1 from \cf2 sklearn.model_selection \cf1 import \cf2 train_test_split\line\cf1 from \cf2 sklearn.metrics \cf1 import \cf2 accuracy_score, confusion_matrix\line\cf1 import \cf2 matplotlib.pyplot \cf1 as \cf2 plt\line\cf1 from \cf2 matplotlib \cf1 import \cf2 colors\line\line\cf1 def \cf3 minmax_scaler\cf2 (data):\line     \cf4 # Separate numeric and non-numeric columns\line     \cf2 numeric_cols = data.select_dtypes(\cf5 include\cf2 =np.number).columns\line     non_numeric_cols = \cf6 list\cf2 (\cf6 set\cf2 (data.columns) - \cf6 set\cf2 (numeric_cols))\line\line     \cf4 # Scale numeric columns\line     \cf2 numeric_data = data[numeric_cols]\line     scaler = MinMaxScaler()\line     scaled_numeric = scaler.fit_transform(numeric_data)\line\line     \cf4 # Check for and replace NaN and infinite values\line     \cf2 scaled_numeric = np.nan_to_num(scaled_numeric)\line\line     \cf4 # One-hot encode non-numeric columns\line     \cf2 non_numeric_data = pd.get_dummies(data[non_numeric_cols])\line\line     \cf4 # Concatenate scaled numeric and one-hot encoded non-numeric data\line     \cf2 scaled_data = np.concatenate([scaled_numeric, non_numeric_data], \cf5 axis\cf2 =\cf7 1\cf2 )\line\line     \cf1 return \cf2 scaled_data\line\line\cf1 def \cf3 e_distance\cf2 (x, y):\line     \cf1 if \cf2 x.ndim > \cf7 1\cf2 :\line         x = x.flatten()\line     \cf1 if \cf2 y.ndim > \cf7 1\cf2 :\line         y = y.flatten()\line     \cf1 return \cf2 distance.euclidean(x, y)\line\line\cf1 def \cf3 m_distance\cf2 (x, y):\line     \cf1 return \cf2 distance.cityblock(x, y)\line\line\cf1 def \cf3 winning_neuron\cf2 (data, t, som, num_rows, num_cols):\line     winner = [\cf7 0\cf2 , \cf7 0\cf2 ]\line     shortest_distance = np.sqrt(data.shape[\cf7 1\cf2 ])\line     input_data = data[t][:, np.newaxis] \cf1 if \cf2 data[t].ndim == \cf7 1 \cf1 else \cf2 data[t]\line     \cf1 for \cf2 row \cf1 in \cf6 range\cf2 (num_rows):\line         \cf1 for \cf2 col \cf1 in \cf6 range\cf2 (num_cols):\line             dist = e_distance(som[row][col], input_data)\line             \cf1 if \cf2 dist < shortest_distance:\line                 shortest_distance = dist\line                 winner = [row, col]\line     \cf1 return \cf2 winner\line\line\cf1 def \cf3 decay\cf2 (step, max_steps, max_learning_rate, max_neighbourhood_range):\line     coefficient = \cf7 1.0 \cf2 - (np.float64(step) / max_steps)\line     learning_rate = coefficient * max_learning_rate\line     neighbourhood_range = ceil(coefficient * max_neighbourhood_range)\line     \cf1 return \cf2 learning_rate, neighbourhood_range\line\line\cf1 def \cf3 som_training\cf2 (train_data, num_rows, num_cols, max_neighbourhood_range, max_learning_rate, max_steps):\line     num_dims = train_data.shape[\cf7 1\cf2 ]\line     np.random.seed(\cf7 40\cf2 )\line     som = np.random.random_sample(\cf5 size\cf2 =(num_rows, num_cols, num_dims))\line\line     \cf1 for \cf2 step \cf1 in \cf6 range\cf2 (max_steps):\line         \cf1 if \cf2 (step + \cf7 1\cf2 ) % \cf7 1000 \cf2 == \cf7 0\cf2 :\line             \cf6 print\cf2 (\cf8 "Iteration: "\cf2 , step + \cf7 1\cf2 )\line\line         learning_rate, neighbourhood_range = decay(step, max_steps, max_learning_rate, max_neighbourhood_range)\line\line         t = np.random.randint(\cf7 0\cf2 , \cf5 high\cf2 =train_data.shape[\cf7 0\cf2 ])\line         winner = winning_neuron(train_data, t, som, num_rows, num_cols)\line\line         \cf1 for \cf2 row \cf1 in \cf6 range\cf2 (num_rows):\line             \cf1 for \cf2 col \cf1 in \cf6 range\cf2 (num_cols):\line                 \cf1 if \cf2 m_distance([row, col], winner) <= neighbourhood_range:\line                     som[row][col] += learning_rate * (train_data[t] - som[row][col])\line\line     \cf6 print\cf2 (\cf8 "SOM training completed"\cf2 )\line     \cf1 return \cf2 som\line\line\cf1 def \cf3 label_som_nodes\cf2 (train_data_norm, train_y, num_rows, num_cols, som):\line     label_map = np.full((num_rows, num_cols), \cf1 None\cf2 , \cf5 dtype\cf2 =\cf6 object\cf2 )\line\line     \cf1 for \cf2 t \cf1 in \cf6 range\cf2 (train_data_norm.shape[\cf7 0\cf2 ]):\line         winner = winning_neuron(train_data_norm, t, som, num_rows, num_cols)\line         row, col = winner\line         label = train_y.iloc[t].item()  \cf4 # Convert Series to a simple value\line\line         \cf1 if \cf2 label_map[row, col] \cf1 is None\cf2 :\line             label_map[row, col] = [label]\line         \cf1 else\cf2 :\line             label_map[row, col].append(label)\line\line     \cf1 for \cf2 i \cf1 in \cf6 range\cf2 (num_rows):\line         \cf1 for \cf2 j \cf1 in \cf6 range\cf2 (num_cols):\line             \cf1 if \cf2 label_map[i, j] \cf1 is not None\cf2 :\line                 label_map[i, j] = \cf6 max\cf2 (\cf6 set\cf2 (label_map[i, j]), \cf5 key\cf2 =label_map[i, j].count)\line\line     \cf1 return \cf2 label_map\line\line\cf1 def \cf3 evaluate_accuracy\cf2 (test_data, test_y, som, label_map, num_rows, num_cols):\line     winner_labels = []\line\line     \cf1 for \cf2 t \cf1 in \cf6 range\cf2 (test_data.shape[\cf7 0\cf2 ]):\line         input_data = test_data[t][:, np.newaxis] \cf1 if \cf2 test_data[t].ndim == \cf7 1 \cf1 else \cf2 test_data[t]\line         winner = winning_neuron(input_data, t, som, num_rows, num_cols)\line         row = winner[\cf7 0\cf2 ]\line         col = winner[\cf7 1\cf2 ]\line         predicted = label_map[row][col]\line\line         \cf4 # Check for None values and assign a default label if needed\line         \cf1 if \cf2 predicted \cf1 is None\cf2 :\line             predicted = \cf8 'default_label'\line\line         \cf2 winner_labels.append(predicted)\line\line     \cf4 # Convert winner_labels to match the format of test_y\line     \cf2 unique_labels_test = np.unique(test_y)\line     label_dict_test = \{label: idx \cf1 for \cf2 idx, label \cf1 in \cf6 enumerate\cf2 (unique_labels_test)\}\line     winner_labels_numeric = np.array([label_dict_test[label] \cf1 for \cf2 label \cf1 in \cf2 winner_labels])\line\line     accuracy = accuracy_score(test_y, winner_labels_numeric)\line     \cf1 return \cf2 accuracy\line\line\line\line\line\cf4 # Load dataset\line\cf1 from \cf2 ucimlrepo \cf1 import \cf2 fetch_ucirepo\line automobile = fetch_ucirepo(\cf5 id\cf2 =\cf7 10\cf2 )\line X = automobile.data.features\line y = automobile.data.targets\line\line\cf4 # Split the dataset into training and testing sets\line\cf2 train_x, test_x, train_y, test_y = train_test_split(X, y, \cf5 test_size\cf2 =\cf7 0.2\cf2 , \cf5 random_state\cf2 =\cf7 42\cf2 )\line\cf6 print\cf2 (train_x.shape, train_y.shape, test_x.shape, test_y.shape)  \cf4 # check the shapes\line\line # Hyperparameters for SOM\line\cf2 num_rows = \cf7 10\line\cf2 num_cols = \cf7 10\line\cf2 max_neighbourhood_range = \cf7 4\line\cf2 max_learning_rate = \cf7 0.5\line\cf2 max_steps = \cf6 int\cf2 (\cf7 7.5 \cf2 * \cf7 10e3\cf2 )\line\line\cf4 # Train SOM\line\cf2 train_data = pd.concat([train_x, train_y], \cf5 axis\cf2 =\cf7 1\cf2 )\line train_data_norm = minmax_scaler(train_data)\line som = som_training(train_data_norm, num_rows, num_cols, max_neighbourhood_range, max_learning_rate, max_steps)\line\line\cf4 # Label the SOM nodes\line\cf2 label_map = label_som_nodes(train_data_norm, train_y, num_rows, num_cols, som)\line\line\cf4 # Evaluate accuracy on the test set\line\cf2 test_data_norm = minmax_scaler(test_x)\line accuracy = evaluate_accuracy(test_data_norm, test_y, som, label_map, num_rows, num_cols)\line\line\cf6 print\cf2 (\cf8 "Accuracy: "\cf2 , accuracy)\line\par

\pard\sa200\sl276\slmult1\cf0\f1\fs22\par
}
 